ADR-WCF-010a: Overall Testing Philosophy
Status: ACCEPTED
Date: 2025-06-01 (Final version incorporating detailed feedback on integration test categorization, OpenAPI role, DB testing specifics, E2E scope, AI-assisted testing, accessibility, test data management, and Flutter testing nuances)
Authors: WorldChef Development Team
1. Context and Problem Statement
To ensure the WorldChef application (Flutter client - ADR-WCF-001a; Fastify API backend - ADR-WCF-001c & ADR-WCF-003) is reliable, maintainable, and meets quality standards, a comprehensive testing philosophy is required. This philosophy guides the types of tests, their scope, and integration into the development lifecycle, balancing thoroughness with MVP development velocity. This ADR outlines this overall philosophy, with ADR-WCF-010b detailing specific tooling. Key principles from the existing Test Strategy.txt document are formalized and expanded here.
2. Decision Drivers
Quality & Reliability: Minimize production bugs; ensure features work as expected.
Prevent Regressions: New changes must not break existing functionality.
Confidence in Releases: Enable frequent, confident deployments.
Maintainability & Documentation: Well-tested code is easier to refactor; tests serve as executable documentation.
Developer Velocity & Fast Feedback: Efficient testing practices should support rapid development.
Cost-Effectiveness: Optimize testing effort on high-impact areas.
NFR Validation: Ensure performance, security, and accessibility targets are met.
3. Decision: Testing Philosophy
WorldChef will adopt a testing philosophy primarily based on the Test Pyramid, with a strong emphasis on pragmatic and valuable integration tests at different levels.
Overall Test Volume: Unit tests will be most numerous, followed by various integration tests, with E2E tests being the fewest.
Strong Foundation of Unit Tests:
Scope:
Backend (Fastify): Individual functions, helper utilities, pure business logic modules (e.g., within services, tested in isolation with their direct, non-framework dependencies potentially mocked), Fastify route handler logic (request parsing, validation, service calls with services themselves mocked, response formatting).
Client (Flutter): Individual Dart classes/functions (e.g., models, utility functions, business logic within BLoCs/Cubits/Providers with their direct dependencies mocked). For Flutter widgets at a unit level: testing the direct logic or state management class of a widget, without deep UI rendering or interaction with child widgets.

Goal: Verify correctness of isolated code units. Provide very fast feedback.

Strategic & Valuable Integration Tests (Multiple Levels):
A. Backend Component Integration (Fastify):
Scope: Test interaction between Fastify API route handlers and their underlying service classes/modules (e.g., RecipeService). Dependencies of the service (like database access layers or external client SDKs) are mocked/stubbed.
Goal: Verify that components within the Fastify application wire together correctly and contracts between them are met.

B. Backend Persistence Integration (Fastify Service <> Supabase DB):
Scope: Test Fastify service logic interacting with an actual PostgreSQL database instance. This will use TestContainers (or similar local ephemeral database solutions like Dockerized Postgres seeded with migrations). Each test or test suite should run within its own transaction that is rolled back at the end, ensuring test isolation.
Goal: Validate SQL queries, data transformations, RLS policy interactions (with test user contexts), and overall data persistence logic.

C. Client-API Contract & Integration (Flutter <> Mock API):
Scope: Test Flutter service layers/repositories responsible for API communication against a mocked Fastify API server (e.g., using http_mock_adapter for Dio). Mock API responses must conform to the OpenAPI specification.
Goal: Verify client-side request construction, response parsing, error handling, and data model mapping. Client-side validation of received API responses against schemas derived from OpenAPI is encouraged.

D. UI Component Integration (Flutter Widget Tests):
Scope: Test compositions of multiple Flutter widgets interacting, verifying UI behavior, state flow, and basic navigation within a significant portion of a screen or a self-contained feature. Flutter's testWidgets framework is ideal for this (runs headlessly and fast). This includes "golden file" testing for UI consistency where appropriate.
Goal: Ensure UI components render correctly together and respond to user interactions as expected within a bounded context.


Focused End-to-End (E2E) Tests (Flutter Client â†” Live Test Backend):
Scope: Critical user paths (P0 functionality) through the entire system: Flutter client interacting with the Fastify API connected to a dedicated, controlled test Supabase database (seeded with known data).
Examples for MVP: User Registration & Login; View Recipe List & Detail; Create Recipe (Creator); Basic Subscription Flow.

Goal: Verify complete user flows work. Act as a final quality gate. Focus on "happy paths" for MVP; complex error/edge cases are better covered at lower levels.
Flakiness Mitigation: Use stable test data, explicit wait strategies (no fixed sleeps), robust widget finders, and potentially limited retry logic for known transient issues.

Contract Adherence (via OpenAPI & Schema Validation):
Primary Mechanism: The Fastify API (ADR-WCF-015) will use JSON Schema validation for all incoming requests and outgoing responses, derived from/contributing to an OpenAPI specification. The Flutter client will generate data models from this OpenAPI spec or ensure its models align.
Specialized Contract Testing (e.g., Pact): Deferred for MVP, as robust OpenAPI schema validation provides strong contract guarantees for the initial phase.

Performance Tests (Targeted): (Details in Test Strategy.txt / Future Performance ADR).
Security Tests: (Details in Test Strategy.txt / ADR-WCF-016 Security).
Accessibility Tests (A11y): (Details in Test Strategy.txt). Includes automated linting/analysis and manual testing with assistive technologies (VoiceOver/TalkBack) for P0 flows.
Guiding Principles for Test Implementation:
Tests are first-class citizens: written alongside or before new code. Test for bug fixes.
FIRST Principles: Fast, Independent, Repeatable, Self-Validating, Timely (i.e., written with the production code).
Test behavior, not implementation details. Prioritize tests providing most value.
Clear, descriptive test names.
AI-Assisted Testing: Leverage AI for generating unit test stubs, boilerplate, test cases for pure functions, and data variations. All AI-generated tests, especially for logic, require careful human review and refinement to ensure they correctly capture intent, cover edge cases, and are not merely superficial.
Test Data Management: For database integration and E2E tests, a clear strategy for seeding data (e.g., fixtures, factories), isolating tests (e.g., transactional rollback for integration tests, dedicated user accounts per E2E scenario), and cleaning test data is essential.
5. Rationale
This philosophy provides a balanced approach:
Fast Feedback & Debuggability: Unit tests, Flutter widget tests, and backend component integration tests offer quick feedback and easier debugging.
Confidence in Interactions: Multiple levels of integration tests validate component interactions.
Pragmatic E2E for MVP: Focused E2E tests ensure core flows work without excessive burden.
Leveraging Platform Strengths: Utilizes Flutter's widget testing and TestContainers for DB testing.
Clear Contract Enforcement: Prioritizes OpenAPI schema validation.
AI Augmentation with Oversight: Realistically incorporates AI for test generation.
6. Consequences
Positive Consequences / Benefits:
Higher code quality, reliability, and maintainability.
Reduced regressions. Increased developer confidence.
Faster feedback loops during development.
Negative Consequences / Trade-offs / Risks:
Time Investment: Comprehensive testing is an ongoing effort. (Accepted for quality).
Complex Integration Test Setup: TestContainers, mock APIs require initial setup.
E2E Test Maintenance: Requires careful design and upkeep.
AI-Generated Test Quality: Risk of superficial tests if human review is inadequate.
7. Validation / Success Metrics
Consistently high pass rates for automated tests in CI (CI pipeline detailed in ADR-WCF-011).
Reduction in regression bugs. Key NFRs validated.
Developers report tests provide useful feedback and confidence.
Achieving pragmatic code coverage targets (e.g., backend business logic >80%, critical Flutter state/logic >70%) as indicators of discipline, not sole quality measures. High coverage on poorly written tests is not a goal.
E2E tests for P0 flows pass reliably pre-release.
Successful, reliable use of TestContainers for DB integration tests.
8. Review / Revisit
After each major development cycle: Review effectiveness, feedback speed, test suite health.
If CI build/test times become excessively long: (May trigger test optimization, CI parallelization, infrastructure upgrades for CI runners, or re-evaluation of test distribution).
If bug rates in production increase or regressions become common.
Annually, to align with evolving project needs and testing best practices.


